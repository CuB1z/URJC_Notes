---
tags: URJC URJC_IC
---

# Tema 1 - IngenierÃ­a del Conocimiento

---

## Tabla de Contenidos

1. [Â¿QuÃ© es la Inteligencia Artificial?](#Â¿QuÃ©%20es%20la%20Inteligencia%20Artificial?)
2. [Inteligencia Artificial](#Inteligencia%20Artificial)
3. [Pensar como humanos](#Pensar%20como%20humanos)
4. [Actuar como humanos](#Actuar%20como%20humanos)
5. [Actuar de forma racional](#Actuar%20de%20forma%20racional)
6. [Historia de la Inteligencia Artificial](#Historia%20de%20la%20Inteligencia%20Artificial)
7. [Agentes](#Agentes)
8. [Agente Inteligente](#Agente%20Inteligente)
9. [Programa y Arquitectura de Agente](#Programa%20y%20Arquitectura%20de%20Agente)
10. [Propiedades de entorno](#Propiedades%20de%20entorno)

---

## Â¿QuÃ© es la Inteligencia Artificial?

> **ðŸ¤– Inteligencia Artificial**
> Intento de reproducir inteligencia (humana) mediante mÃ©todos computacionales, buscando desarrollar sistemas capaces de aprender, razonar y tomar decisiones de manera autÃ³noma.

---

## Inteligencia Artificial

> **ðŸŽ¯ Objetivo**
> Estudiar los entes inteligentes.
> - _CientÃ­fico_: Entender los entes inteligentes.
> - _Ingenieril_: Construir entes inteligentes.

Otras definiciones enunciadas en la historia:

> **ðŸ§  Sistemas que piensan como humanos**
> _"La interesante tarea de lograr que las computadores piensen...
> MÃ¡quinas con mente, en su amplio sentido literal"_
> (Haugeland 1985)

> **ðŸ¤– Sistemas que actÃºan como humanos**
> _"El arte de crear mÃ¡quinas con capacidad de realizar funciones que
> realizadas por personas requieren inteligencia"_
> (Kurzweil 1990)

> **ðŸ§© Sistemas que actÃºan de forma racional**
> _"La rama de la InformÃ¡tica que se ocupa de la automatizaciÃ³n del
> comportamiento inteligente"_
> (Luger & Stubblefield 1993)

---

## Pensar como humanos

> **ðŸ§  Modelado Congitivo**
> - Abrir la "caja negra" de la mente humana.
> - Analizar los procesos mentales (introspecciÃ³n, experimentos).
> - Desarrollar una teorÃ­a acerca de los procesos mentales.
> - Aplicar esta teorÃ­a en la simulaciÃ³n de dichos procesos en un ordenador.

> **ðŸ§© General Problem Solver (GPS)**
>  _[Newell & Simon 1961]_
>  
> - Resuelve problemas mediante la descomposiciÃ³n en subproblemas mÃ¡s simples.
> - Se centra en la comparaciÃ³n de los pasos de razonamiento del GPS con los pasos seguidos por una persona al resolver el mismo problema.

> **ðŸ§ª Ciencia Cognitiva**
> - Modelos computacionales (IA) + tÃ©cnicas experimentales (psicologÃ­a).
> - Construir teorÃ­as rigurosas y verificables acerca de los procesos mentales.

---

## Actuar como humanos

> **ðŸ§  Prueba de Turing**
>  _[Alan Turing 1950]_
>  
> - Un evaluador humano y un interlocutor estÃ¡n separados por una mampara.
> - El interlocutor puede ser bien otra persona o bien un ordenador.
> - El evaluador formula preguntas a travÃ©s de un teletipo, y el interlocutor da sus respuestas del mismo modo.
> - El ordenador supera la prueba, si el evaluador no es capaz de distinguir entre Ã©l y un humano.

---

## Actuar de forma racional

> **ðŸ§  Racionalidad**
> - _Prescriptivo_: Como las personas deberÃ­an actuar.
> - _Sentido estricto_: Â¿CÃ³mo sacar "conclusiones verdaderas"?
> - _Sentido amplio_: Â¿CÃ³mo actuar y "sobrevivir" en un entorno?

> **ðŸ§© Pensar de forma Racional**
> - _Leyes de pensamiento de AristÃ³teles_: Razonamiento irrefutable.
> - _LÃ³gica formal_: Lenguaje formal para representar todo tipo de entes en el mundo y un modelo riguroso para razonar sobre dichos entes.
> - Sistemas basados en mÃ©todos computacionales de inferencia lÃ³gica, programaciÃ³n lÃ³gica.

> **ðŸ¤– Actuar de forma racional**
> - Sistemas que requieren acciones racionales.

> **ðŸ§  Agentes Racionales**
> - Enfoque relativo al contexto de actuar de forma "correcta" en un entorno.
> - Las acciones no tienen por quÃ© determinarse mediante inferencia lÃ³gica.
> - Sistemas que generan acciones que son eficientes en su entorno con respecto a unos valores / objetivos.

> **ðŸŽ¯ Ventajas**
> - Pone Ã©nfasis en una perspectiva _ingenieril_.
> - Proporciona criterios transparentes para evaluar conducta inteligente.
> - Destaca la relaciÃ³n entre comportamientos inteligentes y el entorno en el que se desarrollan (_nociÃ³n gradual de inteligencia_).
> - Permite una concepciÃ³n integrada de las distintas tÃ©cnicas y subÃ¡reas de la Inteligencia Artificial.

---

## Historia de la Inteligencia Artificial

> **ðŸ“œ 1940 ~ 1950**
> - Programas que resuelven tareas bÃ¡sicas de razonamiento (jugar ajedrez / jugar damas / probar teoremas geomÃ©tricos).
> - Primeros modelos de neuronas artificiales (McCulloch & Pitts 1943).
> - _Conferencia de Darthmouth, EEUU (1956)_
> 	- AcuÃ±a el tÃ©rmino "Inteligencia Artificial".
> 	- John McCarthy, Marvin Minsky, Cluade Shannon, Allen Newell, ...

> **ðŸ“œ 1960 ~ 1970**
> - General Problem Solver (GPS) (Newell & Simon 1961).
> - Entrenamiento de redes neuronales simples (Rosenblatt 1962).
> - Representaciones especializadas del conocimiento (reglas, marcos, guiones).
> - Primeros sistemas expertos (Dendral, Propector, Mycin).
> - Declive de la computaciÃ³n neuronal (AnÃ¡lisis de los Perceptrones de Minsky).

> **ðŸ“œ 1970 ~ 1980**
> - La Inteligencia Artificial entra en la industria
> 	- Aplicaciones comerciales de los sistemas expertos.
> 	- Proyecto de software de "5Âª GeneraciÃ³n" para crear ordenadores inteligentes en JapÃ³n.
> - No se cumplen las promesas: "Invierno de IA".

> **ðŸ“œ 1990**
> - Regreso de las redes neuronales (algoritmo de propagaciÃ³n hacia atrÃ¡s).
> - Modelos rigurosos y computacionalmentre eficientes de manejo de incertidumbre (cadenas de Markov, redes Bayesianas).
> - La investigaciÃ³n se centra mÃ¡s en construir artefactos Ãºtiles en lugar de resolver el problema de la "IA general".

> **ðŸ“œ 2000**
> - Cambio de interÃ©s de sde la _IA SimbÃ³lica_ a la _IA Conexionista / Machine Learning_.
> - Aumento de capacidad computacional + aumento de datos e informaciÃ³n (internet) llevan a nuevos resultados.
> - _Big Data_: Algoritmos de aprendizaje automÃ¡tico para grandes volÃºmenes de datos.
> - _Deep Learning (2010)_
> 	- Redes con mÃºltiples capas y "niveles" de aprendizaje.
> - Ã‰xitos relevantes en Machine Learning
> - La Inteligencia Artificial entra en la vida diaria
> 	- Sistemas autÃ³nomos: RobÃ³tica, vehÃ­culos autÃ³nomos, sistemas multiagente.
> 	- IA generativa (ChatGPT, Dall-E).

---

## Agentes

> **ðŸ¤– Agente**
> Ente activo embebido en un entorno.
> - _Cuerpo_
> 	- Percibe el entorno por medio de sensores.
> 	- ActÃºa sobre el entorno por medio de efectores.
> - _Mente_
> 	- Determina las acciones a partir de las percepciones.
> 	- Medida de rendimiento que guÃ­a dicho proceso.

Existen dos tipos de agentes:

> **ðŸŒ± Agentes Naturales**
> - Cuerpo biolÃ³gico y entorno natural.
> - _Sensores_: Ojos, oÃ­dos, lengua, etc.
> - _Efectores_: Piernas, brazos, manos, etc.
> - _Medida de rendimiento_: Sobrevivir, reproducirse, etc.

> **ðŸ¤– Agentes Artificiales**
> 1. Agentes Hardware (Robots)
> 	- InteractÃºan directamente con un entorno fÃ­sico.
> 	- Disponen de un "cuerpo" fÃ­sico.
> 	- _Sensores_: CÃ¡maras, telÃ©metros infrarrojos, etc.
> 	- _Efectores_: Ruedas / piernas, manipuladores, etc.
> 2. Agentes Software (Softbots)
> 	- ActÃºan en entornos virtuales como Internet.
> 	- _Todo es software_: No necesitan manipular fisicamente el entorno.
> 	- _Sensores y efectores_: Dependientes del entorno.

---

## Agente Inteligente

> **ðŸ¤– Agentes Inteligentes**
> - ActÃºan de forma racional en su entorno.
> - Determinantes de un comportamiento racional
> 	- _Medida de rendimiento_: Define el grado de Ã©xito del agente.
> 	- _Secuencia de percepciones_: La experiencia del agente.
> 	- _Capacidades_: Las acciones que el agente pueda emprender.
> 	- Conocimiento a priori sobre su entorno.

> **ðŸ§  Comportamiento Racional**
> A partir de la secuencia de percepciones hasta el momento, y el conocimiento a priori sobre el entorno, elegir entre las capacidades la acciÃ³n que maximice la medida de rendimiento.

> **ðŸ¤” Racionalidad â‰  Omnisciencia**
> La selecciÃ³n racional de acciones sÃ³lo se basa en la informaciÃ³n disponible.

> **â“ Problema**
> Los conocimientos a priori compilan la "inteligencia" del diseÃ±ador un agente que no presta atenciÃ³n a sus percepciones.
> - No serÃ­a inteligente.
> - SÃ³lo podrÃ­a actuar en entornos extremadamente simples.
> - No puede actuar con Ã©xito en situaciones no anticipadas.

> **ðŸ”„ AutonomÃ­a**
> "No bajo el control inmediato de una persona" un agente es mÃ¡s _autÃ³nomo_
> - Cuanto mÃ¡s se rige su comportamiento por su propia experiencia.
> - Cuanto menos depende de sus conocimiento a priori.

> **ðŸ¤– Agente Inteligente = Comportamiento Racional + AutonomÃ­a**

---

## Programa y Arquitectura de Agente

> **ðŸ’» Programas de Agente**
> Software que determina el comportamiento del agente, y que implementa la funciÃ³n percepciÃ³n-acciÃ³n.
> 
> ```pseudocode
> {simple agent program}
> memory <- perceive(memory, percept)
> action <- action-selection(memory, performance-measure)
> memory <- act(memory, action)
> ```

> **ðŸ—ï¸ Arquitectura de Agente**
> - Los mÃ³dulos que componen el agente.
> - Estructura el programa de agente.
> - Partes imprescindibles
> 	- Componente de percepciÃ³n.
> 	- Componente de selecciÃ³n de acciones.
> 	- Componente de acciÃ³n.

---

## Propiedades de entorno

> **ðŸŒ Accesible / Inaccesible**
> _Â¿El agente puede determinar inequÃ­vocamente el estado de su entorno?_
> - Accesible: Ajedrez, Tres en raya.
> - Inaccesible: PÃ³ker, laberinto, videojuego.

> **ðŸ”„ Determinista / No Determinista**
> _Â¿Las acciones del agente en un estado actual determinan completamente el estado resultante?_
> - Determinista: Ajedrez, agente software en entorno simulado.
> - No Determinista: GestiÃ³n de trÃ¡fico, robot en sala real.

> **ðŸ•’ EstÃ¡tico / DinÃ¡mico**
> _Â¿El estado del entorno puede cambiar mientras el agente delibera? Â¿Puede cambiar sin que el agente actÃºe?_
> - EstÃ¡tico: Agente software en un laberinto simulado (entorno no cambia).
> - SemidinÃ¡mico: Ajedrez (cambios previsibles).
> - DinÃ¡mico: GestiÃ³n de trÃ¡fico (cambios imprevisibles).

> **ðŸ”¢ Discreto / Continuo**
> _Â¿Los conjuntos de posibles percepciones y/o acciones son discretos (estados finitos)?_
> - Discreto: Ajedrez, agente software en un laberinto simulado.
> - Continuo: Robot navegando en una sala real.

---